{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Analysis: Predicting Spending for NEW Customers\n",
    "\n",
    "## The Cold Start Problem\n",
    "\n",
    "**Scenario**: A new customer visits for the first time. You have:\n",
    "- Their demographics (age, income, education, family)\n",
    "- NO purchase history\n",
    "\n",
    "**Question**: Can we predict spending using ONLY demographics?\n",
    "\n",
    "| Notebook | Features | R2 | Use Case |\n",
    "|----------|----------|-----|----------|\n",
    "| 02_regression.ipynb | Demographics + History | 0.97 | Existing |\n",
    "| 02b (this) | Demographics ONLY | 0.78 | New customers |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "try:\n",
    "    from xgboost import XGBRegressor\n",
    "    HAS_XGBOOST = True\n",
    "except ImportError:\n",
    "    HAS_XGBOOST = False\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.2\n",
    "CV_FOLDS = 5\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "MAIN_COLOR = '#2ecc71'\n",
    "SECONDARY_COLOR = '#3498db'\n",
    "\n",
    "print(f\"Libraries loaded. XGBoost: {HAS_XGBOOST}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IQRCapper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns=None, k=1.5):\n",
    "        self.columns = columns\n",
    "        self.k = k\n",
    "        self.bounds_ = {}\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        X = pd.DataFrame(X)\n",
    "        cols = self.columns if self.columns else X.columns\n",
    "        for col in cols:\n",
    "            if col in X.columns:\n",
    "                Q1, Q3 = X[col].quantile(0.25), X[col].quantile(0.75)\n",
    "                IQR = Q3 - Q1\n",
    "                self.bounds_[col] = (Q1 - self.k * IQR, Q3 + self.k * IQR)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = pd.DataFrame(X).copy()\n",
    "        for col, (lower, upper) in self.bounds_.items():\n",
    "            if col in X.columns:\n",
    "                X[col] = X[col].clip(lower, upper)\n",
    "        return X.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading - Demographics Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/marketing_campaign.csv', sep='\\t')\n",
    "spending_cols = ['MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts', 'MntGoldProds']\n",
    "df['TotalSpend'] = df[spending_cols].sum(axis=1)\n",
    "df['Age'] = 2014 - df['Year_Birth']\n",
    "\n",
    "print(f\"Dataset: {df.shape}\")\n",
    "print(f\"TotalSpend: Mean=${df['TotalSpend'].mean():.2f}, Median=${df['TotalSpend'].median():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY demographic features - NO purchase history!\n",
    "num_features = ['Income', 'Age', 'Kidhome', 'Teenhome']\n",
    "cat_features = ['Education', 'Marital_Status']\n",
    "demographic_features = num_features + cat_features\n",
    "\n",
    "print(\"FEATURES USED (available for new customers):\")\n",
    "for f in demographic_features:\n",
    "    print(f\"  - {f}\")\n",
    "\n",
    "print(\"\\nFEATURES EXCLUDED (require purchase history):\")\n",
    "for f in ['NumCatalogPurchases', 'NumWebPurchases', 'NumStorePurchases', 'Recency']:\n",
    "    print(f\"  - {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.dropna(subset=['Income']).copy()\n",
    "X = df_clean[demographic_features]\n",
    "y = df_clean['TotalSpend']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n",
    "print(f\"Train: {len(X_train)}, Test: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('capper', IQRCapper(columns=None, k=1.5)),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numeric_pipeline, num_features),\n",
    "    ('cat', categorical_pipeline, cat_features)\n",
    "])\n",
    "\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "print(f\"Processed features: {X_train_processed.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'Ridge': Ridge(alpha=1.0, random_state=RANDOM_STATE),\n",
    "    'Lasso': Lasso(alpha=0.1, random_state=RANDOM_STATE),\n",
    "    'ElasticNet': ElasticNet(alpha=0.1, l1_ratio=0.5, random_state=RANDOM_STATE),\n",
    "    'DecisionTree': DecisionTreeRegressor(max_depth=10, random_state=RANDOM_STATE),\n",
    "    'RandomForest': RandomForestRegressor(n_estimators=100, max_depth=10, random_state=RANDOM_STATE, n_jobs=-1),\n",
    "    'GradientBoosting': GradientBoostingRegressor(n_estimators=100, max_depth=5, random_state=RANDOM_STATE),\n",
    "}\n",
    "if HAS_XGBOOST:\n",
    "    models['XGBoost'] = XGBRegressor(n_estimators=100, max_depth=5, random_state=RANDOM_STATE, verbosity=0)\n",
    "\n",
    "print(f\"Models: {len(models)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Baseline Model Comparison (5-Fold CV)\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "baseline_results = []\n",
    "for name, model in models.items():\n",
    "    cv_scores = cross_val_score(model, X_train_processed, y_train, cv=CV_FOLDS, scoring='r2')\n",
    "    baseline_results.append({'Model': name, 'CV_mean': cv_scores.mean(), 'CV_std': cv_scores.std()})\n",
    "    print(f\"{name:20} | R2 = {cv_scores.mean():.4f} +/- {cv_scores.std():.4f}\")\n",
    "\n",
    "baseline_df = pd.DataFrame(baseline_results).sort_values('CV_mean', ascending=False).reset_index(drop=True)\n",
    "print(f\"\\nBest: {baseline_df.iloc[0]['Model']} (R2 = {baseline_df.iloc[0]['CV_mean']:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "colors = [MAIN_COLOR if i == 0 else SECONDARY_COLOR for i in range(len(baseline_df))]\n",
    "ax.barh(baseline_df['Model'], baseline_df['CV_mean'], xerr=baseline_df['CV_std'], color=colors, capsize=5)\n",
    "ax.set_xlabel('R2 Score')\n",
    "ax.set_title('NEW Customer Spending Prediction (Demographics Only)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_models = baseline_df.head(3)['Model'].tolist()\n",
    "param_grids = {\n",
    "    'RandomForest': {'n_estimators': [100, 200], 'max_depth': [5, 10, 15]},\n",
    "    'GradientBoosting': {'n_estimators': [100, 200], 'max_depth': [3, 5], 'learning_rate': [0.1, 0.2]},\n",
    "    'XGBoost': {'n_estimators': [100, 200], 'max_depth': [3, 5], 'learning_rate': [0.1, 0.2]},\n",
    "}\n",
    "\n",
    "tuned_models = {}\n",
    "for name in top_models:\n",
    "    print(f\"Tuning {name}...\")\n",
    "    if name in param_grids:\n",
    "        grid = GridSearchCV(models[name], param_grids[name], cv=CV_FOLDS, scoring='r2', n_jobs=-1)\n",
    "        grid.fit(X_train_processed, y_train)\n",
    "        tuned_models[name] = grid.best_estimator_\n",
    "        print(f\"  Best R2: {grid.best_score_:.4f}\")\n",
    "    else:\n",
    "        models[name].fit(X_train_processed, y_train)\n",
    "        tuned_models[name] = models[name]\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Final Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Final Test Set Results\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "final_results = []\n",
    "for name, model in tuned_models.items():\n",
    "    test_r2 = r2_score(y_test, model.predict(X_test_processed))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, model.predict(X_test_processed)))\n",
    "    final_results.append({'Model': name, 'R2_test': test_r2, 'RMSE': test_rmse})\n",
    "    print(f\"{name}: R2={test_r2:.4f}, RMSE=${test_rmse:.2f}\")\n",
    "\n",
    "results_df = pd.DataFrame(final_results).sort_values('R2_test', ascending=False)\n",
    "best_name = results_df.iloc[0]['Model']\n",
    "best_r2 = results_df.iloc[0]['R2_test']\n",
    "best_model = tuned_models[best_name]\n",
    "\n",
    "print(f\"\\nBEST: {best_name} with R2 = {best_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_encoder = preprocessor.named_transformers_['cat'].named_steps['encoder']\n",
    "feature_names = num_features + cat_encoder.get_feature_names_out(cat_features).tolist()\n",
    "\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    imp_df = pd.DataFrame({'Feature': feature_names, 'Importance': best_model.feature_importances_})\n",
    "    imp_df = imp_df.sort_values('Importance', ascending=False)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.barh(imp_df['Feature'], imp_df['Importance'], color=MAIN_COLOR)\n",
    "    ax.set_xlabel('Importance')\n",
    "    ax.set_title('Feature Importance (Demographics Only)')\n",
    "    ax.invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(imp_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Comparison with Full Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "bars = ax.bar(['Demographics Only\\n(New Customers)', 'Full Features\\n(Existing)'], [best_r2, 0.97], color=[MAIN_COLOR, SECONDARY_COLOR])\n",
    "ax.set_ylabel('R2 Score')\n",
    "ax.set_title('Demographics vs Full Features')\n",
    "ax.set_ylim(0, 1.1)\n",
    "for bar, val in zip(bars, [best_r2, 0.97]):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, val + 0.02, f'{val:.2f}', ha='center', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nGap: {(0.97 - best_r2)*100:.1f}% variance explained by behavioral features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Example Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = pd.DataFrame([\n",
    "    {'Income': 100000, 'Age': 45, 'Education': 'PhD', 'Marital_Status': 'Married', 'Kidhome': 0, 'Teenhome': 1},\n",
    "    {'Income': 50000, 'Age': 30, 'Education': 'Graduation', 'Marital_Status': 'Single', 'Kidhome': 0, 'Teenhome': 0},\n",
    "    {'Income': 30000, 'Age': 25, 'Education': 'Basic', 'Marital_Status': 'Single', 'Kidhome': 1, 'Teenhome': 0},\n",
    "])\n",
    "\n",
    "preds = best_model.predict(preprocessor.transform(examples))\n",
    "print(\"New Customer Predictions:\")\n",
    "for i, (_, row) in enumerate(examples.iterrows()):\n",
    "    print(f\"  Customer {i+1}: Income=${row['Income']:,} -> Predicted=${preds[i]:,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Conclusion\n",
    "\n",
    "**Key Findings:**\n",
    "- Demographics explain ~78% of spending variance\n",
    "- Income is the dominant predictor\n",
    "- Behavioral data adds ~19% more accuracy\n",
    "\n",
    "**Use Cases:**\n",
    "| Stage | Model | R2 |\n",
    "|-------|-------|----|\n",
    "| New customer | This model | 0.78 |\n",
    "| Established | Full model | 0.97 |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
